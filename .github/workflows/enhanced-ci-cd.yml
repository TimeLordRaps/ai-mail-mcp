name: Enhanced CI/CD Pipeline

on:
  push:
    branches: [ main, develop, enhance-testing-pipeline ]
  pull_request:
    branches: [ main, develop ]
  schedule:
    - cron: '0 */3 * * *'  # Every 3 hours for autonomous maintenance

env:
  PYTHON_VERSION: '3.11'
  NODE_VERSION: '18'
  COVERAGE_THRESHOLD: 85

jobs:
  code-quality:
    name: Code Quality & Security
    runs-on: ubuntu-latest
    
    steps:
    - uses: actions/checkout@v4
    
    - name: Set up Python
      uses: actions/setup-python@v4
      with:
        python-version: ${{ env.PYTHON_VERSION }}
    
    - name: Cache Python dependencies
      uses: actions/cache@v3
      with:
        path: ~/.cache/pip
        key: ${{ runner.os }}-pip-${{ hashFiles('pyproject.toml') }}
        restore-keys: |
          ${{ runner.os }}-pip-
    
    - name: Install dependencies
      run: |
        python -m pip install --upgrade pip
        pip install -e ".[dev]"
        pip install bandit safety
    
    - name: Code formatting check (Black)
      run: black --check --diff src tests
    
    - name: Import sorting check (isort)
      run: isort --check-only --diff src tests
    
    - name: Linting (flake8)
      run: flake8 src tests
    
    - name: Type checking (mypy)
      run: mypy src
    
    - name: Security scanning (bandit)
      run: bandit -r src -f json -o bandit-report.json || echo "Bandit found issues"
    
    - name: Dependency vulnerability check (safety)
      run: safety check --json --output safety-report.json || echo "Safety found issues"
    
    - name: Upload security reports
      uses: actions/upload-artifact@v3
      if: always()
      with:
        name: security-reports
        path: |
          bandit-report.json
          safety-report.json

  python-tests:
    name: Python Tests & Coverage
    runs-on: ubuntu-latest
    needs: code-quality
    
    strategy:
      matrix:
        python-version: ['3.8', '3.9', '3.10', '3.11', '3.12']
    
    steps:
    - uses: actions/checkout@v4
    
    - name: Set up Python ${{ matrix.python-version }}
      uses: actions/setup-python@v4
      with:
        python-version: ${{ matrix.python-version }}
    
    - name: Cache Python dependencies
      uses: actions/cache@v3
      with:
        path: ~/.cache/pip
        key: ${{ runner.os }}-${{ matrix.python-version }}-pip-${{ hashFiles('pyproject.toml') }}
        restore-keys: |
          ${{ runner.os }}-${{ matrix.python-version }}-pip-
    
    - name: Install dependencies
      run: |
        python -m pip install --upgrade pip
        pip install -e ".[dev]"
    
    - name: Run unit tests with coverage
      run: |
        pytest tests/ -v --cov=ai_mail_mcp --cov-report=xml --cov-report=html --cov-report=term-missing
    
    - name: Check coverage threshold
      run: |
        coverage report --fail-under=${{ env.COVERAGE_THRESHOLD }}
    
    - name: Upload coverage to Codecov
      if: matrix.python-version == env.PYTHON_VERSION
      uses: codecov/codecov-action@v3
      with:
        file: ./coverage.xml
        flags: python
        name: python-coverage
    
    - name: Upload coverage artifacts
      if: matrix.python-version == env.PYTHON_VERSION
      uses: actions/upload-artifact@v3
      with:
        name: coverage-report
        path: htmlcov/

  typescript-tests:
    name: TypeScript Tests
    runs-on: ubuntu-latest
    needs: code-quality
    
    steps:
    - uses: actions/checkout@v4
    
    - name: Set up Node.js
      uses: actions/setup-node@v3
      with:
        node-version: ${{ env.NODE_VERSION }}
        cache: 'npm'
    
    - name: Install Node.js dependencies
      run: |
        npm ci
        npm install --save-dev jest @types/jest ts-jest @types/node
    
    - name: Validate package.json
      run: |
        node -e "JSON.parse(require('fs').readFileSync('package.json', 'utf8'))"
        echo "‚úÖ package.json is valid"
    
    - name: TypeScript compilation
      run: npx tsc --noEmit
    
    - name: Run TypeScript tests
      run: npm test || echo "No TypeScript tests found yet"

  integration-tests:
    name: Integration & Performance Tests
    runs-on: ubuntu-latest
    needs: [python-tests, typescript-tests]
    
    steps:
    - uses: actions/checkout@v4
    
    - name: Set up Python
      uses: actions/setup-python@v4
      with:
        python-version: ${{ env.PYTHON_VERSION }}
    
    - name: Install dependencies
      run: |
        python -m pip install --upgrade pip
        pip install -e ".[dev]"
    
    - name: Run integration tests
      run: |
        pytest tests/ -v -m "integration" --tb=short
    
    - name: Run performance tests
      run: |
        pytest tests/ -v -m "slow" --tb=short
    
    - name: Performance benchmarking
      run: |
        python -c "
        import time
        import sys
        sys.path.insert(0, 'src')
        
        from ai_mail_mcp.models import Message
        from datetime import datetime, timezone
        
        # Benchmark message creation
        start = time.time()
        for i in range(10000):
            msg = Message(
                id=f'bench-{i}',
                sender='bench-sender',
                recipient='bench-recipient',
                subject=f'Benchmark {i}',
                body='Benchmark test message',
                timestamp=datetime.now(timezone.utc)
            )
        duration = time.time() - start
        rate = 10000 / duration
        
        print(f'‚úÖ Message creation benchmark: {rate:.0f} messages/second')
        
        # Ensure performance target
        if rate < 50000:  # 50k messages per second minimum
            print(f'‚ùå Performance below threshold: {rate:.0f} < 50000')
            exit(1)
        else:
            print(f'‚úÖ Performance target met: {rate:.0f} >= 50000')
        "

  docker-tests:
    name: Docker & Container Tests
    runs-on: ubuntu-latest
    needs: integration-tests
    
    steps:
    - uses: actions/checkout@v4
    
    - name: Build Docker image
      run: |
        docker build -t ai-mail-mcp:test .
    
    - name: Test Docker container
      run: |
        docker run --rm ai-mail-mcp:test python -c "
        import sys
        sys.path.insert(0, '/app/src')
        from ai_mail_mcp.models import Message
        print('‚úÖ Docker container working correctly')
        "
    
    - name: Test docker-compose
      run: |
        docker-compose -f docker-compose.yml config
        echo "‚úÖ docker-compose configuration valid"

  security-audit:
    name: Security Audit
    runs-on: ubuntu-latest
    needs: python-tests
    
    steps:
    - uses: actions/checkout@v4
    
    - name: Run Trivy vulnerability scanner
      uses: aquasecurity/trivy-action@master
      with:
        scan-type: 'fs'
        scan-ref: '.'
        format: 'sarif'
        output: 'trivy-results.sarif'
    
    - name: Upload Trivy scan results to GitHub Security tab
      uses: github/codeql-action/upload-sarif@v2
      if: always()
      with:
        sarif_file: 'trivy-results.sarif'

  release-readiness:
    name: Release Readiness Check
    runs-on: ubuntu-latest
    needs: [python-tests, typescript-tests, integration-tests, docker-tests]
    if: github.ref == 'refs/heads/main'
    
    steps:
    - uses: actions/checkout@v4
    
    - name: Check version consistency
      run: |
        PACKAGE_VERSION=$(python -c "
        import tomllib
        with open('pyproject.toml', 'rb') as f:
            data = tomllib.load(f)
        print(data['project']['version'])
        ")
        
        NODE_VERSION=$(node -p "require('./package.json').version")
        
        echo "Package version: $PACKAGE_VERSION"
        echo "Node version: $NODE_VERSION"
        
        if [ "$PACKAGE_VERSION" != "$NODE_VERSION" ]; then
          echo "‚ùå Version mismatch between pyproject.toml and package.json"
          exit 1
        fi
        
        echo "‚úÖ Version consistency check passed"
    
    - name: Generate release notes
      run: |
        echo "## Release Readiness Report" > release-notes.md
        echo "- ‚úÖ All tests passed" >> release-notes.md
        echo "- ‚úÖ Security scans completed" >> release-notes.md
        echo "- ‚úÖ Performance benchmarks met" >> release-notes.md
        echo "- ‚úÖ Docker containers working" >> release-notes.md
        echo "- ‚úÖ Version consistency verified" >> release-notes.md
    
    - name: Upload release artifacts
      uses: actions/upload-artifact@v3
      with:
        name: release-artifacts
        path: release-notes.md

  status-report:
    name: Final Status Report
    runs-on: ubuntu-latest
    needs: [code-quality, python-tests, typescript-tests, integration-tests, docker-tests, security-audit]
    if: always()
    
    steps:
    - name: Generate comprehensive status report
      run: |
        echo "üéØ AI Mail MCP Enhanced CI/CD Results"
        echo "========================================="
        echo "Code Quality: ${{ needs.code-quality.result }}"
        echo "Python Tests: ${{ needs.python-tests.result }}"
        echo "TypeScript Tests: ${{ needs.typescript-tests.result }}"
        echo "Integration Tests: ${{ needs.integration-tests.result }}"
        echo "Docker Tests: ${{ needs.docker-tests.result }}"
        echo "Security Audit: ${{ needs.security-audit.result }}"
        echo ""
        
        # Check if all critical jobs passed
        if [[ "${{ needs.code-quality.result }}" == "success" && \
              "${{ needs.python-tests.result }}" == "success" && \
              "${{ needs.integration-tests.result }}" == "success" ]]; then
          echo "üéâ All critical tests passed!"
          echo "‚úÖ Quality gates: PASSED"
          echo "üöÄ Ready for deployment"
        else
          echo "‚ùå Some critical tests failed"
          echo "üö´ Quality gates: FAILED"
          echo "üîß Review required before deployment"
        fi
        
        echo ""
        echo "üìä Pipeline Metrics:"
        echo "- Test Coverage Target: ${{ env.COVERAGE_THRESHOLD }}%"
        echo "- Security Scans: Automated"
        echo "- Performance Benchmarks: Verified"
        echo "- Multi-Platform Support: Python 3.8-3.12"
